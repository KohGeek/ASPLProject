{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Notebook\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import xml_to_dict as xtd\n",
    "\n",
    "# Define the paths\n",
    "test_dir = './datasets/test'\n",
    "output_test_dir = './datasets/test_cropped'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_test_dir):\n",
    "    os.makedirs(output_test_dir)\n",
    "\n",
    "ori_rendered_path = os.path.abspath('../Backup/1 - rendered_images')\n",
    "ori_aspl_path = os.path.abspath('../Backup/1 - aspl_images')\n",
    "\n",
    "rendered_path = os.path.abspath('./datasets/rendered')\n",
    "aspl_path = os.path.abspath('./datasets/aspl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process CVAT labelled data for YOLOv8 training\n",
    "\n",
    "The provided data by ASPL was labelled through rotated bounding box. However, rotated/oriented bounding box remains to be a frontier of research and there is not a lot of format supporting it.\n",
    "\n",
    "Thus, this is an attempt to convert from LabelMe format to YOLO OBB/Segmentation format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_cvat(search_dir):\n",
    "    obj_idx_dict = {\n",
    "            \"Main Pad\": 0,\n",
    "            \"LED Pads\": 1,\n",
    "            \"Main Chip\": 2,\n",
    "            \"Left LED Chip\": 3,\n",
    "            \"Right LED Chip\": 3,\n",
    "            # \"Main PCB\": 5\n",
    "        }\n",
    "\n",
    "    parser = xtd.XMLtoDict()\n",
    "\n",
    "    for root, _, files in os.walk(search_dir):\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            if file.endswith(\".xml\"):\n",
    "\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_name = file.split(\".\")[0]\n",
    "\n",
    "                with open(file_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                xml_dict = parser.parse(content)['annotation']\n",
    "\n",
    "                img_x = int(xml_dict['imagesize']['ncols'])\n",
    "                img_y = int(xml_dict['imagesize']['nrows'])\n",
    "\n",
    "                with open(os.path.join(root, file_name + '.txt'), 'w') as f:\n",
    "\n",
    "                    for obj in xml_dict['object']:\n",
    "                        \n",
    "                        if obj['name'] not in obj_idx_dict:\n",
    "                            continue\n",
    "\n",
    "                        obj_name = obj['name']\n",
    "                        points = []\n",
    "\n",
    "                        for pt in obj['polygon']['pt']:\n",
    "                            points.append((float(pt['x']), float(pt['y'])))\n",
    "\n",
    "                        angle = obj['attributes'].split(',')[0].split('=')[1]\n",
    "                        rect = cv2.RotatedRect(points[0], points[1], points[2])\n",
    "                        rect.angle = float(angle)\n",
    "                        verts = [f\"{vert:.8f}\" for vert in np.multiply(cv2.boxPoints(rect), [1/img_x, 1/img_y]).flatten().tolist()]\n",
    "                    \n",
    "                        f.write(f'{str(obj_idx_dict[obj_name])} {\" \".join(verts)}\\n')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Rendered data for YOLOv8 training\n",
    "\n",
    "Rendered data is already compatible with YOLO OBB/Segmentation format.\n",
    "\n",
    "However, mistakes were made during rendering and broke the labels, this was subsequently fixed with the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_rendered():\n",
    "    img_dir = os.path.abspath('./datasets/rendered')\n",
    "    lbl_dir = os.path.abspath('./datasets/rendered/labels')\n",
    "\n",
    "    val_dir = os.path.abspath('./datasets/rendered/val')\n",
    "    train_dir = os.path.abspath('./datasets/rendered/train')\n",
    "\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "\n",
    "    file_list = [file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "    random.shuffle(file_list)\n",
    "    n_files = len(file_list)\n",
    "\n",
    "    for i, item in enumerate(file_list):\n",
    "        \n",
    "        item_name = item.split('.')[0]\n",
    "        img_path = os.path.join(img_dir, item)\n",
    "        lbl_path = os.path.join(lbl_dir, item_name + '.txt')\n",
    "\n",
    "        if i < n_files * 0.2:\n",
    "            shutil.move(img_path, os.path.join(val_dir, item))\n",
    "            shutil.move(lbl_path, os.path.join(val_dir, item_name + '.txt'))\n",
    "        else:\n",
    "            shutil.move(img_path, os.path.join(train_dir, item))\n",
    "            shutil.move(lbl_path, os.path.join(train_dir, item_name + '.txt'))\n",
    "\n",
    "        if (i - 1) % 100 == 0 or i == n_files - 1:\n",
    "            print(f\"{i+1} / {n_files} files processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def fix_labels(search_dir):\n",
    "    for root, _, files in os.walk(search_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                labels = []\n",
    "\n",
    "                with open(file_path, 'r') as f:\n",
    "                    labels = f.read().splitlines()\n",
    "\n",
    "                new_labels = []\n",
    "                for label in labels:\n",
    "                    label = label.split(' ')\n",
    "                    label = [ float(x) for x in label ]\n",
    "                    label[0] = int(label[0])\n",
    "\n",
    "                    ori_label = label.copy()\n",
    "\n",
    "                    if label[0] == 2:\n",
    "                        label[2] = 1-ori_label[2]\n",
    "                        label[4] = 1-ori_label[4]\n",
    "                        label[6] = 1-ori_label[6]\n",
    "                        label[8] = 1-ori_label[8]\n",
    "                    else:\n",
    "                        label[1] = ori_label[1]\n",
    "                        label[2] = 1-ori_label[2]\n",
    "                        label[3] = ori_label[5]\n",
    "                        label[4] = 1-ori_label[6]\n",
    "                        label[5] = ori_label[7]\n",
    "                        label[6] = 1-ori_label[8]\n",
    "                        label[7] = ori_label[3]\n",
    "                        label[8] = 1-ori_label[4]\n",
    "\n",
    "                    new_labels.append(' '.join([str(x) for x in label]))\n",
    "\n",
    "                    print(label)\n",
    "                \n",
    "                with open(file_path, 'w') as f:\n",
    "                    for label in new_labels:\n",
    "                        f.write(label + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Labels\n",
    "\n",
    "Code below is used to process all labels, like removing PCB and unifying different classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def remove_pcb(files, root):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            with open(file_path, 'w') as f:\n",
    "                for line in lines:\n",
    "                    if line.split()[0] != '5':\n",
    "                        f.write(line) \n",
    "\n",
    "def rename_4_to_3(files, root):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            with open(file_path, 'w') as f:\n",
    "                for line in lines:\n",
    "                    if line.split()[0] == '4':\n",
    "                        line = '3 ' + ' '.join(line.split()[1:]) + '\\n'\n",
    "                    f.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Train, Test, and Validation\n",
    "\n",
    "Functions to allow splitting of data into train, test, and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## copy files from a list to a specified directory\n",
    "def copy_files(files, directory):\n",
    "    x = 0\n",
    "   \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for file in files:\n",
    "        shutil.copy(file, directory)\n",
    "        x += 1\n",
    "        if x % 25 == 0 or x == len(files):\n",
    "            print(\"Copied {} files. Last file copied was {}\".format(x, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the functions\n",
    "\n",
    "### Copying images\n",
    "\n",
    "Copying images from its original backup to the dataset location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, process the ASPL XML labels to YOLO format\n",
    "# Then, find all txt labels from ASPL and move them to the same folder with the images correspondingly\n",
    "\n",
    "process_cvat(ori_aspl_path)\n",
    "\n",
    "all_txt_labels = {}\n",
    "\n",
    "for root, _, files in os.walk(ori_aspl_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            all_txt_labels[file.split('.')[0]] = os.path.join(root, file)\n",
    "\n",
    "for root, _, files in os.walk(ori_aspl_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            shutil.copy(all_txt_labels[file.split('.')[0]], root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of files to copy:\n",
    "# Rendered - Get 600 good, 400 bad, and 200 mirage\n",
    "# ASPL - Use all\n",
    "\n",
    "# Split ratio:\n",
    "# Rendered - 85% train, 15% val\n",
    "# ASPL - 70% train, 20% val, 10% test\n",
    "\n",
    "aspl = []\n",
    "\n",
    "for root, _, files in os.walk(ori_aspl_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            file = file.split('.')[0]\n",
    "            aspl.append((file, root))\n",
    "\n",
    "random.shuffle(aspl)\n",
    "\n",
    "aspl_train = aspl[:int(0.7*len(aspl))]\n",
    "aspl_val = aspl[int(0.7*len(aspl)):int(0.9*len(aspl))]\n",
    "aspl_test = aspl[int(0.9*len(aspl)):]\n",
    "\n",
    "aspl_files = {\n",
    "    'train': aspl_train,\n",
    "    'val': aspl_val,\n",
    "    'test': aspl_test\n",
    "}\n",
    "\n",
    "for type in aspl_files:\n",
    "    if not os.path.exists(os.path.join(aspl_path, type)):\n",
    "        os.makedirs(os.path.join(aspl_path, type))\n",
    "\n",
    "    for file in aspl_files[type]:\n",
    "        shutil.copy(os.path.join(file[1], file[0] + '.jpg'), os.path.join(aspl_path, type))\n",
    "        shutil.copy(os.path.join(file[1], file[0] + '.txt'), os.path.join(aspl_path, type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_rendered = []\n",
    "bad_rendered = []\n",
    "mirage_rendered = []\n",
    "\n",
    "for root, _, files in os.walk(ori_rendered_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            file = file.split('.')[0]\n",
    "            if 'good' in root:\n",
    "                good_rendered.append((file, root))\n",
    "            elif 'bad' in root:\n",
    "                bad_rendered.append((file, root))\n",
    "            elif 'mirage' in root:\n",
    "                mirage_rendered.append((file, root))\n",
    "\n",
    "\n",
    "random.shuffle(good_rendered)\n",
    "random.shuffle(bad_rendered)\n",
    "random.shuffle(mirage_rendered)\n",
    "\n",
    "rendered_train = good_rendered[:510] + bad_rendered[:340] + mirage_rendered[:170]\n",
    "rendered_val = good_rendered[510:600] + bad_rendered[340:400] + mirage_rendered[170:200]\n",
    "\n",
    "rendered_files = {\n",
    "    'train': rendered_train,\n",
    "    'val': rendered_val\n",
    "}\n",
    "\n",
    "for type in rendered_files:\n",
    "    if not os.path.exists(os.path.join(rendered_path, type)):\n",
    "        os.makedirs(os.path.join(rendered_path, type))\n",
    "\n",
    "    for file in rendered_files[type]:\n",
    "        shutil.copy(os.path.join(file[1], file[0] + '.png'), os.path.join(rendered_path, type))\n",
    "        shutil.copy(os.path.join(file[1], file[0] + '.txt'), os.path.join(rendered_path, type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_render_tests_path = os.path.abspath('../Backup/!rendered_original/tests')\n",
    "\n",
    "control = []\n",
    "nocomp = []\n",
    "somecomp = []\n",
    "\n",
    "for root, _, files in os.walk(ori_render_tests_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            file = file.split('.')[0]\n",
    "            if 'control' in root:\n",
    "                control.append((file, root))\n",
    "            elif 'nocomp' in root:\n",
    "                nocomp.append((file, root))\n",
    "            elif 'somecomp' in root:\n",
    "                somecomp.append((file, root))\n",
    "\n",
    "random.shuffle(control)\n",
    "random.shuffle(nocomp)\n",
    "random.shuffle(somecomp)\n",
    "\n",
    "dest_render_tests_path = os.path.abspath('./datasets/render_tests')\n",
    "\n",
    "# copy 170 of each to their respective folders train\n",
    "# copy 30 of each to their respective folders val\n",
    "\n",
    "render_tests_files = {\n",
    "    'control': control,\n",
    "    'nocomp': nocomp,\n",
    "    'somecomp': somecomp\n",
    "}\n",
    "\n",
    "for type in render_tests_files:\n",
    "    if not os.path.exists(os.path.join(dest_render_tests_path, type)):\n",
    "        os.makedirs(os.path.join(dest_render_tests_path, type))\n",
    "\n",
    "    for x, file in enumerate(render_tests_files[type]):\n",
    "        if x < 170:\n",
    "            if not os.path.exists(os.path.join(dest_render_tests_path, type, 'train')):\n",
    "                os.makedirs(os.path.join(dest_render_tests_path, type, 'train'))\n",
    "            shutil.copy(os.path.join(file[1], file[0] + '.png'), os.path.join(dest_render_tests_path, type, 'train'))\n",
    "            shutil.copy(os.path.join(file[1], file[0] + '.txt'), os.path.join(dest_render_tests_path, type, 'train'))\n",
    "        else:\n",
    "            if not os.path.exists(os.path.join(dest_render_tests_path, type, 'val')):\n",
    "                os.makedirs(os.path.join(dest_render_tests_path, type, 'val'))\n",
    "            shutil.copy(os.path.join(file[1], file[0] + '.png'), os.path.join(dest_render_tests_path, type, 'val'))\n",
    "            shutil.copy(os.path.join(file[1], file[0] + '.txt'), os.path.join(dest_render_tests_path, type, 'val'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename class 4 to 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for root, _, files in os.walk(aspl_path):\n",
    "    rename_4_to_3(files, root)\n",
    "\n",
    "for root, _, files in os.walk(rendered_path):\n",
    "    rename_4_to_3(files, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath('./datasets/render_tests')\n",
    "\n",
    "for root, _, files in os.walk(directory):\n",
    "    rename_4_to_3(files, root)\n",
    "fix_labels(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV\n",
    "\n",
    "Crop some of the validation images with rotation to check whether the model is robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_x = 100\n",
    "# crop_y = 775\n",
    "# crop_width = 520\n",
    "# crop_height = 320\n",
    "\n",
    "def augment_test(output):\n",
    "    # Iterate over the validation images\n",
    "    for file in os.listdir(test_dir):\n",
    "        if file.endswith('.jpg'):\n",
    "\n",
    "            # Read the image\n",
    "            image_path = os.path.join(test_dir, file)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "            # Read the corresponding label file\n",
    "            with open(os.path.join(test_dir, file.split('.')[0] + '.txt'), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            shapes = []\n",
    "            for i, line in enumerate(lines):\n",
    "                if line[0] == '0' or line[0] == '2':\n",
    "                    continue\n",
    "\n",
    "                line = line.split()\n",
    "\n",
    "                points = []\n",
    "                for j in range(1, len(line), 2):\n",
    "                    line[j] = float(line[j])*image.shape[1]\n",
    "                    line[j+1] = float(line[j+1])*image.shape[0]\n",
    "                    points.append([line[j], line[j+1]])\n",
    "                shapes.append((line[0],points))\n",
    "\n",
    "\n",
    "\n",
    "            # Define the cropping parameters\n",
    "            crop_x = int(random.gauss(70, 8))  # Crop starting x-coordinate\n",
    "            crop_y = int(random.gauss(750, 15))  # Crop starting y-coordinate\n",
    "            crop_width = int(random.gauss(550, 15))  # Crop width\n",
    "            crop_height = int(random.gauss(350, 10))  # Crop height\n",
    "            rotate_angle = random.gauss(90, 50)-90\n",
    "\n",
    "\n",
    "            # Define the rotation matrix\n",
    "            M = cv2.getRotationMatrix2D((crop_width/2, crop_height/2), rotate_angle, 1)\n",
    "\n",
    "            r = np.deg2rad(rotate_angle)\n",
    "            newX,newY = (abs(np.sin(r)*crop_height) + abs(np.cos(r)*crop_width),abs(np.sin(r)*crop_width) + abs(np.cos(r)*crop_height))\n",
    "            \n",
    "\n",
    "            (tx,ty) = ((newX-crop_width)/2,(newY-crop_height)/2)\n",
    "            M[0,2] += tx #third column of matrix holds translation, which takes effect after rotation.\n",
    "            M[1,2] += ty\n",
    "\n",
    "\n",
    "\n",
    "            # Cropping of image and points\n",
    "            cropped_image = image[crop_y:crop_y+crop_height, crop_x:crop_x+crop_width]\n",
    "\n",
    "            for i, (_, shape) in enumerate(shapes):\n",
    "                for j, point in enumerate(shape):\n",
    "                    x = point[0] - crop_x\n",
    "                    y = point[1] - crop_y\n",
    "\n",
    "                    shapes[i][1][j] = [x, y]\n",
    "\n",
    "            # plt.imshow(cropped_image)\n",
    "            # for _, shape in shapes:\n",
    "            #     plt.plot(*zip(*shape), marker='o', color='r')\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            # Rotation of image and points\n",
    "            rotated_image = cv2.warpAffine(cropped_image, M, dsize=(int(newX), int(newY)))\n",
    "\n",
    "            for i, (_, shape) in enumerate(shapes):\n",
    "                shape = np.array([shape])\n",
    "                shape = cv2.transform(shape, M)\n",
    "                shapes[i] = (shapes[i][0], shape[0])\n",
    "\n",
    "            # plt.imshow(rotated_image)\n",
    "            # for _, shape in shapes:\n",
    "            #     plt.plot(*zip(*shape), marker='o', color='r')\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "            # Save the data\n",
    "            img_output_path = os.path.join(output, file)\n",
    "            cv2.imwrite(img_output_path, rotated_image)\n",
    "\n",
    "            lbl_output_path = os.path.join(output, file.split('.')[0] + '.txt')\n",
    "            with open(lbl_output_path, 'w') as f:\n",
    "                for id, shape in shapes:\n",
    "                    f.write(f'{id} {shape[0][0]/newX} {shape[0][1]/newY} {shape[1][0]/newX} {shape[1][1]/newY} {shape[2][0]/newX} {shape[2][1]/newY} {shape[3][0]/newX} {shape[3][1]/newY}\\n')\n",
    "\n",
    "augment_test(output_test_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASPLProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
